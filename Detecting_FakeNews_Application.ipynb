{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc54bc6f-8406-4592-bfc5-205c9d33df3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load data from '/Users/chandu/Downloads/fakeNews.csv'...\n",
      "✓ Data loaded successfully.\n",
      "✓ Loaded all 9900 articles from the dataset.\n",
      "\n",
      "========================================\n",
      "  Fake News Detector CLI\n",
      "========================================\n",
      "  Model Status: Not Trained\n",
      "----------------------------------------\n",
      "1. Train Model\n",
      "2. Classify an Article\n",
      "3. Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1-3):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Model ---\n",
      "✓ Building neural network and preprocessing data...\n",
      "✓ Data split: 7920 training, 1980 validation samples.\n",
      "✓ Vectorized text and added 2 engineered features.\n",
      "⚡ Starting training...\n",
      "Epoch 1/9 - Loss: 4.0312, Accuracy: 49.51%, Val Accuracy: 49.49%\n",
      "Epoch 2/9 - Loss: 2.7350, Accuracy: 54.23%, Val Accuracy: 53.84%\n",
      "Epoch 3/9 - Loss: 2.2934, Accuracy: 86.09%, Val Accuracy: 84.85%\n",
      "Epoch 4/9 - Loss: 1.3486, Accuracy: 96.34%, Val Accuracy: 96.67%\n",
      "Epoch 5/9 - Loss: 2.0458, Accuracy: 96.89%, Val Accuracy: 96.82%\n",
      "Epoch 6/9 - Loss: 2.1652, Accuracy: 71.26%, Val Accuracy: 71.16%\n",
      "Epoch 7/9 - Loss: 1.5745, Accuracy: 95.80%, Val Accuracy: 96.31%\n",
      "Epoch 8/9 - Loss: 1.3587, Accuracy: 93.46%, Val Accuracy: 93.38%\n",
      "Epoch 9/9 - Loss: 0.9784, Accuracy: 81.14%, Val Accuracy: 80.40%\n",
      "\n",
      "✓ Training complete! Final Validation Accuracy: 80.40%\n",
      "\n",
      "--------------- Detailed Validation Metrics ---------------\n",
      "\n",
      "Confusion Matrix:\n",
      "               Predicted Real  Predicted Fake\n",
      "Actual Real    978             2              \n",
      "Actual Fake    386             614            \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Real (0)       0.72      1.00      0.83       980\n",
      "    Fake (1)       1.00      0.61      0.76      1000\n",
      "\n",
      "    accuracy                           0.80      1980\n",
      "   macro avg       0.86      0.81      0.80      1980\n",
      "weighted avg       0.86      0.80      0.80      1980\n",
      "\n",
      "-------------------------------------------------------\n",
      "----------------------\n",
      "\n",
      "========================================\n",
      "  Fake News Detector CLI\n",
      "========================================\n",
      "  Model Status: Trained (Val Acc: 80.40%)\n",
      "----------------------------------------\n",
      "1. Train Model\n",
      "2. Classify an Article\n",
      "3. Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1-3):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classify Article ---\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste the news article text here:\n",
      ">   BUSTED: Trump Supporter Used Poll Watcher Credentials To Force Early Voters To Leave Polling Place Clearly, there is no low Trump supporters won t stoop in the effort to get him elected president.Ever since the Republican nominee told his deplorable supporters that the election is  rigged  and that they should become poll watchers there has been multiple incidents of voter intimidation, voter suppression, and voter fraud by Trump supporters and even an act of violence against a polling place.And another Trump supporter just got caught trying to intimidate early voters into leaving an Arkansas polling place.Thus far, early voting has benefited Hillary Clinton and that s a big deal with only four days left until Election Day. So Jefferson County Election Commission Stu Soffer, who is a Trump supporter, used his poll watcher credentials and stood in a doorway to yell at early voters at the Pine Bluff polling location to leave. Shut up and go home,  Soffer yelled while blocking the entrance to the voting booths according to Jefferson County Clerk Patricia Johnson and a voter named Victor who did not get to cast his ballot because of Soffer s interference. As a result of the disruption and confusion caused by Stu Soffer and other Republicans   I was not able to cast my ballot that day,  Victor said.According to attorney Chris Burke, who represents Victor in the lawsuit filed against Soffer,  Mr. Soffer stood in the doorway of the early-voting location and told voters to shut up and go home. As a result, Victor and many other voters were unable to cast their votes that day. This is deeply troubling to the voters of Jefferson County and also to the election administrators whose job it is to administer the elections free of fear and intimidation,  Burke added.This is just the latest incident of a Trump supporter trying to rig the election for Donald Trump.In Green Bay, Wisconsin a city clerk tried to deny a request for an extra polling place near the local university solely on the grounds that she believes college students are more likely to vote for Democrats.In Iowa, a Trump supporter literally got caught trying to vote twice and was arrested.And a right-wing group is creating fake badges so they can infiltrate polling places in order to intimidate voters on Election Day for Trump.These incidents, including this recent one in Arkansas prove that Trump supporters are trying to rig the election for their candidate and it s only going to get worse in the days ahead, especially on Election Day as conservatives desperately try to secure a victory for the Republican nominee by hook or by crook.Featured Image: Facebook\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing...\n",
      "\n",
      "--- Prediction Result ---\n",
      "  Label: Fake News\n",
      "  Confidence: 65.52%\n",
      "-------------------------\n",
      "\n",
      "========================================\n",
      "  Fake News Detector CLI\n",
      "========================================\n",
      "  Model Status: Trained (Val Acc: 80.40%)\n",
      "----------------------------------------\n",
      "1. Train Model\n",
      "2. Classify an Article\n",
      "3. Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1-3):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting application.\n"
     ]
    }
   ],
   "source": [
    "### -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "This script provides a command-line interface to train a fake news classifier\n",
    "and predict whether a given news article is real or fake. It mirrors the\n",
    "functionality of the original React component.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import string\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Suppress convergence warnings from MLPClassifier for a cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "class FakeNewsClassifier:\n",
    "    \"\"\"\n",
    "    A classifier for detecting fake news using a combination of TF-IDF\n",
    "    vectorization, simple feature engineering, and a Multi-layer Perceptron model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the vectorizer and the neural network model.\"\"\"\n",
    "        # TF-IDF Vectorizer to convert text into numerical features\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            stop_words='english',\n",
    "            max_features=5000,\n",
    "            ngram_range=(1, 2)\n",
    "        )\n",
    "        # MLPClassifier serves as our neural network\n",
    "        self.model = MLPClassifier(\n",
    "            hidden_layer_sizes=(128, 64),\n",
    "            activation='relu',\n",
    "            solver='adam',\n",
    "            max_iter=1,          # Train one epoch at a time in a loop\n",
    "            warm_start=True,     # Retain weights between 'fit' calls\n",
    "            random_state=42,\n",
    "            learning_rate_init=0.001,\n",
    "            alpha=0.0001\n",
    "        )\n",
    "        self.is_trained = False\n",
    "        self.validation_accuracy = 0.0\n",
    "\n",
    "    def _feature_engineering(self, texts):\n",
    "        \"\"\"\n",
    "        Creates additional numerical features from the text.\n",
    "        Args:\n",
    "            texts (list of str): A list of text documents.\n",
    "        Returns:\n",
    "            np.array: An array of engineered features for each text.\n",
    "        \"\"\"\n",
    "        engineered_features = []\n",
    "        for text in texts:\n",
    "            text_len = len(text)\n",
    "            # Avoid division by zero for empty strings\n",
    "            if text_len == 0:\n",
    "                punc_density = 0\n",
    "            else:\n",
    "                punc_count = sum(1 for char in text if char in string.punctuation)\n",
    "                punc_density = punc_count / text_len\n",
    "            \n",
    "            engineered_features.append([text_len, punc_density])\n",
    "            \n",
    "        return np.array(engineered_features)\n",
    "\n",
    "    def train(self, texts, labels, validation_split=0.2, epochs=20):\n",
    "        \"\"\"\n",
    "        Trains the model on the provided data, preventing data leakage.\n",
    "        Args:\n",
    "            texts (list of str): The news article texts.\n",
    "            labels (list of int): The corresponding labels (0 for real, 1 for fake).\n",
    "            validation_split (float): The proportion of data to use for validation.\n",
    "            epochs (int): The number of training epochs.\n",
    "        \"\"\"\n",
    "        print(\"✓ Building neural network and preprocessing data...\")\n",
    "\n",
    "        # 1. Split data into training and validation sets FIRST to prevent leakage\n",
    "        X_train_text, X_val_text, y_train, y_val = train_test_split(\n",
    "            texts, labels, test_size=validation_split, random_state=42, stratify=labels\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ Data split: {len(X_train_text)} training, {len(X_val_text)} validation samples.\")\n",
    "\n",
    "        # 2. Fit and transform the vectorizer ONLY on the training data\n",
    "        X_train_tfidf = self.vectorizer.fit_transform(X_train_text).toarray()\n",
    "        \n",
    "        # 3. Transform the validation data using the FITTED vectorizer\n",
    "        X_val_tfidf = self.vectorizer.transform(X_val_text).toarray()\n",
    "\n",
    "        # 4. Create engineered features for both sets separately\n",
    "        X_train_eng = self._feature_engineering(X_train_text)\n",
    "        X_val_eng = self._feature_engineering(X_val_text)\n",
    "        print(f\"✓ Vectorized text and added {X_train_eng.shape[1]} engineered features.\")\n",
    "\n",
    "        # 5. Combine TF-IDF features with engineered features for both sets\n",
    "        X_train_combined = np.hstack((X_train_tfidf, X_train_eng))\n",
    "        X_val_combined = np.hstack((X_val_tfidf, X_val_eng))\n",
    "        \n",
    "        print(\"⚡ Starting training...\")\n",
    "        \n",
    "        # 6. Training loop to simulate epoch-by-epoch logging\n",
    "        for epoch in range(epochs):\n",
    "            self.model.fit(X_train_combined, y_train)\n",
    "\n",
    "            # Calculate metrics for logging\n",
    "            train_pred = self.model.predict(X_train_combined)\n",
    "            train_acc = accuracy_score(y_train, train_pred)\n",
    "            val_pred = self.model.predict(X_val_combined)\n",
    "            val_acc = accuracy_score(y_val, val_pred)\n",
    "            loss = self.model.loss_\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}/{epochs} - \"\n",
    "                f\"Loss: {loss:.4f}, \"\n",
    "                f\"Accuracy: {train_acc*100:.2f}%, \"\n",
    "                f\"Val Accuracy: {val_acc*100:.2f}%\"\n",
    "            )\n",
    "\n",
    "            if epoch == epochs - 1:\n",
    "                self.validation_accuracy = val_acc\n",
    "\n",
    "        self.is_trained = True\n",
    "        print(f\"\\n✓ Training complete! Final Validation Accuracy: {self.validation_accuracy*100:.2f}%\")\n",
    "        \n",
    "        # --- Detailed Validation Metrics ---\n",
    "        print(\"\\n\" + \"-\"*15 + \" Detailed Validation Metrics \" + \"-\"*15)\n",
    "        final_val_pred = self.model.predict(X_val_combined)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        cm = confusion_matrix(y_val, final_val_pred)\n",
    "        print(f\"               Predicted Real  Predicted Fake\")\n",
    "        print(f\"Actual Real    {cm[0][0]:<15} {cm[0][1]:<15}\")\n",
    "        print(f\"Actual Fake    {cm[1][0]:<15} {cm[1][1]:<15}\")\n",
    "        \n",
    "        # Classification Report (Precision, Recall, F1-score)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_val, final_val_pred, target_names=['Real (0)', 'Fake (1)']))\n",
    "        print(\"-\" * 55)\n",
    "\n",
    "\n",
    "    def predict(self, text):\n",
    "        \"\"\"\n",
    "        Predicts the label for a single piece of text.\n",
    "        Args:\n",
    "            text (str): The news article text to classify.\n",
    "        Returns:\n",
    "            dict: A dictionary containing the predicted 'label' and 'confidence'.\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise NotFittedError(\"Model is not trained. Please train it before making predictions.\")\n",
    "\n",
    "        text_list = [text]\n",
    "        \n",
    "        # Apply the same transformations as in training\n",
    "        engineered_features = self._feature_engineering(text_list)\n",
    "        tfidf_features = self.vectorizer.transform(text_list).toarray()\n",
    "        combined_features = np.hstack((tfidf_features, engineered_features))\n",
    "\n",
    "        # Predict probabilities for [class 0, class 1]\n",
    "        probabilities = self.model.predict_proba(combined_features)[0]\n",
    "        \n",
    "        # We mapped 'real' to 0 and 'fake' to 1\n",
    "        confidence_fake = probabilities[1]\n",
    "        \n",
    "        if confidence_fake > 0.5:\n",
    "            label = \"Fake\"\n",
    "            confidence = confidence_fake\n",
    "        else:\n",
    "            label = \"Real\"\n",
    "            confidence = 1 - confidence_fake\n",
    "            \n",
    "        return {\"label\": label, \"confidence\": confidence}\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the command-line interface.\"\"\"\n",
    "    filepath = '/Users/chandu/Downloads/fakeNews.csv'\n",
    "    \n",
    "    try:\n",
    "        print(f\"Attempting to load data from '{filepath}'...\")\n",
    "        df = pd.read_csv(filepath)\n",
    "        df = df.dropna(subset=['Text', 'label']).reset_index(drop=True)\n",
    "        print(\"✓ Data loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"✗ Error: The file '{filepath}' was not found. Please check the path and try again.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"✗ An error occurred while reading the CSV file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Use the entire loaded dataset\n",
    "    df_sampled = df\n",
    "    print(f\"✓ Loaded all {len(df_sampled)} articles from the dataset.\")\n",
    "\n",
    "    texts = df_sampled['Text'].astype(str).tolist()\n",
    "    labels = [1 if str(label).lower() == 'fake' else 0 for label in df_sampled['label']]\n",
    "\n",
    "    classifier = FakeNewsClassifier()\n",
    "\n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(\"  Fake News Detector CLI\")\n",
    "        print(\"=\"*40)\n",
    "        if classifier.is_trained:\n",
    "             print(f\"  Model Status: Trained (Val Acc: {classifier.validation_accuracy*100:.2f}%)\")\n",
    "        else:\n",
    "             print(\"  Model Status: Not Trained\")\n",
    "        print(\"-\" * 40)\n",
    "        print(\"1. Train Model\")\n",
    "        print(\"2. Classify an Article\")\n",
    "        print(\"3. Exit\")\n",
    "        choice = input(\"Enter your choice (1-3): \")\n",
    "\n",
    "        if choice == '1':\n",
    "            print(\"\\n--- Training Model ---\")\n",
    "            classifier.train(texts, labels, epochs=9) # Reduced epochs to optimal number\n",
    "            print(\"----------------------\")\n",
    "        elif choice == '2':\n",
    "            if not classifier.is_trained:\n",
    "                print(\"\\n[!] Model is not trained. Please train the model first (Option 1).\")\n",
    "                continue\n",
    "\n",
    "            print(\"\\n--- Classify Article ---\")\n",
    "            news_text = input(\"Paste the news article text here:\\n> \")\n",
    "            if not news_text.strip():\n",
    "                print(\"\\n[!] No text provided. Please enter an article.\")\n",
    "                continue\n",
    "\n",
    "            print(\"\\nAnalyzing...\")\n",
    "            try:\n",
    "                result = classifier.predict(news_text)\n",
    "                print(\"\\n--- Prediction Result ---\")\n",
    "                print(f\"  Label: {result['label']} News\")\n",
    "                print(f\"  Confidence: {result['confidence']*100:.2f}%\")\n",
    "                print(\"-------------------------\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\nAn error occurred during prediction: {e}\")\n",
    "\n",
    "        elif choice == '3':\n",
    "            print(\"Exiting application.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"\\n[!] Invalid choice. Please enter a number between 1 and 3.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5a8533-6b59-49db-94da-0ec16080e0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
